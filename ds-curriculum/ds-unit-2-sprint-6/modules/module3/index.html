<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>DS6 Module 3 - Cross-Validation and Grid Search</title>
    <link rel="stylesheet" href="../../assets/css/style.css">
</head>
<body>
    <header>
        <nav>
            <div class="logo">Data Science Unit 2</div>
            <ul class="nav-links">
                <li><a href="../../index.html">Home</a></li>
                <li class="dropdown">
                    <a href="#">Modules</a>
                    <div class="dropdown-content">
                        <a href="../module1/index.html">Module 1: Decision Trees</a>
                        <a href="../module2/index.html">Module 2: Random Forests</a>
                        <a href="../module3/index.html">Module 3: Cross-Validation and Grid Search</a>
                        <a href="../module4/index.html">Module 4: Classification Metrics</a>
                    </div>
                </li>
                <li class="dropdown">
                    <a href="#">Code-Alongs</a>
                    <div class="dropdown-content">
                        <a href="../../code-alongs/index.html#code-along-1">Code-Along 1: Data Wrangling and Encoding</a>
                        <a href="../../code-alongs/index.html#code-along-2">Code-Along 2: Model Tuning</a>
                    </div>
                </li>
                <li><a href="../../sprint-challenge/index.html">Sprint Challenge</a></li>
            </ul>
        </nav>
    </header>

    <main class="container">
        <section id="module-overview">
            <h1>Module 3: Cross-Validation and Grid Search</h1>
            <div class="card">
                <h2>Module Overview</h2>
                <p>In this module, you will learn about cross-validation and hyperparameter optimization techniques that are essential for building robust machine learning models. Cross-validation helps ensure your models generalize well to unseen data, while grid search and randomized search help you find the optimal combination of hyperparameters for your models.</p>
                <p>You'll learn how to implement cross-validation with independent test sets and use scikit-learn's tools for hyperparameter optimization to improve model performance.</p>
            </div>
        </section>

        <section id="objectives">
            <h2>Learning Objectives</h2>
            
            <div class="objective">
                <h3>1. Implement k-fold cross validation</h3>
                <p>Learn how to properly evaluate model performance using cross-validation techniques to ensure your models generalize well to unseen data.</p>
                <ul>
                    <li>Understand the limitations of a single train/validation split</li>
                    <li>Implement k-fold cross-validation</li>
                    <li>Properly integrate cross-validation with data preprocessing pipelines</li>
                    <li>Avoid data leakage between training and test sets</li>
                </ul>
            </div>
            
            <div class="objective">
                <h3>2. Use scikit-learn for hyperparameter optimization</h3>
                <p>Learn how to systematically search for the optimal hyperparameters for your machine learning models using scikit-learn's tools.</p>
                <ul>
                    <li>Understand the concept of hyperparameter tuning</li>
                    <li>Implement GridSearchCV for exhaustive hyperparameter search</li>
                    <li>Implement RandomizedSearchCV for more efficient search</li>
                    <li>Interpret and use the results of hyperparameter optimization</li>
                </ul>
            </div>
        </section>

        <section id="guided-project">
            <h2>Guided Project</h2>
            <div class="card">
                <h3>Cross-Validation</h3>
                <div class="video-container">
                    <iframe class="wistia_embed" title="Sprint 6 Cross-Validation Video" src="https://fast.wistia.net/embed/iframe/83wr347iqm" width="640" height="360" allow="autoplay; fullscreen" loading="lazy"></iframe>
                </div>
                <h4>Resources:</h4>
                <ul>
                    <li><a href="https://github.com/bloominstituteoftechnology/DS-Unit-2-Kaggle-Challenge/tree/main/module3-cross-validation" target="_blank">GitHub Repository</a></li>
                    <li>Guided Project Notebook Name: LS_DS_223.ipynb</li>
                    <li><a href="https://docs.google.com/presentation/d/1tNiykFBXoFErvaes7PFXNp6f5tGsHMgmcSL0qKvTH10/present" target="_blank">Slides</a></li>
                </ul>
            </div>
        </section>

        <section id="module-project">
            <h2>Module Assignment</h2>
            <div class="card">
                <h3>Cross-Validation: Kaggle Competition</h3>
                <p>Continue improving your Kaggle competition submission by implementing cross-validation and hyperparameter optimization.</p>
                <div class="video-container">
                    <iframe class="wistia_embed" title="Cross-Validation - Assignment Video" src="https://fast.wistia.net/embed/iframe/cklm1ufhdx" width="640" height="360" allow="autoplay; fullscreen" loading="lazy"></iframe>
                </div>
                <h4>Assignment Notebook Name: LS_DS_223_assignment.ipynb</h4>
                <h4>Tasks:</h4>
                <ol>
                    <li>Use wrangle function to import training and test data.</li>
                    <li>Split training data into feature matrix X and target vector y.</li>
                    <li>Establish the baseline accuracy score for your dataset.</li>
                    <li>Build clf_dt.</li>
                    <li>Build clf_rf.</li>
                    <li>Evaluate classifiers using k-fold cross-validation.</li>
                    <li>Tune hyperparameters for best performing classifier.</li>
                    <li>Print out best score and params for model.</li>
                    <li>Create submission.csv and upload to Kaggle.</li>
                </ol>
                <p><strong>Libraries to use:</strong> category_encoders, matplotlib, pandas, ydata-profiling, sklearn</p>
                <p><a href="https://github.com/bloominstituteoftechnology/DS-Unit-2-Kaggle-Challenge/tree/main/module3-cross-validation" target="_blank" class="btn">Assignment GitHub Repository</a></p>
            </div>
        </section>

        <section id="additional-resources">
            <h2>Additional Resources</h2>
            <div class="resources">
                <div class="card resource-card">
                    <h3>Documentation</h3>
                    <ul>
                        <li><a href="https://scikit-learn.org/stable/modules/cross_validation.html" target="_blank">Scikit-learn: Cross-validation</a></li>
                        <li><a href="https://scikit-learn.org/stable/modules/grid_search.html" target="_blank">Scikit-learn: Tuning hyperparameters</a></li>
                        <li><a href="https://scikit-learn.org/stable/modules/model_evaluation.html" target="_blank">Scikit-learn: Model evaluation</a></li>
                    </ul>
                </div>
                <div class="card resource-card">
                    <h3>Tutorials</h3>
                    <ul>
                        <li><a href="https://www.kaggle.com/dansbecker/cross-validation" target="_blank">Kaggle: Cross-Validation</a></li>
                    </ul>
                </div>
            </div>
        </section>
    </main>
</body>
</html> 