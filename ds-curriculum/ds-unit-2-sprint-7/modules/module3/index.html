<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>DS7 Module 3 - Permutation and Boosting</title>
    <link rel="stylesheet" href="../../assets/css/style.css">
</head>
<body>
    <header>
        <nav>
            <div class="logo">Data Science Unit 2</div>
            <ul>
                <li><a href="../../index.html">Home</a></li>
                <li class="dropdown">
                    <a href="#" class="active">Modules</a>
                    <div class="dropdown-content">
                        <a href="../module1/index.html">Module 1: Define ML Problems</a>
                        <a href="../module2/index.html">Module 2: Wrangle ML Datasets</a>
                        <a href="../module3/index.html" class="active">Module 3: Permutation and Boosting</a>
                        <a href="../module4/index.html">Module 4: Model Interpretation</a>
                    </div>
                </li>
                <li class="dropdown">
                    <a href="#">Code-Alongs</a>
                    <div class="dropdown-content">
                        <a href="../../code-alongs/index.html#code-along-1">Code-Along 1: Feature Engineering</a>
                        <a href="../../code-alongs/index.html#code-along-2">Code-Along 2: Model Interpretation</a>
                    </div>
                </li>
                <li><a href="../../sprint-challenge/index.html">Sprint Challenge</a></li>
            </ul>
        </nav>
    </header>

    <main>
        <section id="welcome">
            <h1>Module 3: Permutation and Boosting</h1>
            <div class="content-box module3-accent">
                <p>In this module, you'll learn about ensemble methods with a focus on bagging and boosting techniques. You'll understand how gradient boosting models work and how to interpret feature importances through both default and permutation methods. These techniques will help you build more powerful models and gain deeper insights into what drives your predictions.</p>
            </div>
        </section>

        <section>
            <h2>Learning Objectives</h2>
            
            <div class="content-box">
                <h3>1. Bagging vs. Boosting</h3>
                <p>Learn the differences between bagging and boosting approaches to ensemble learning and when to use each technique.</p>
                <ul>
                    <li>Understanding ensemble methods and their advantages</li>
                    <li>Comparing random forests (bagging) with gradient boosting</li>
                    <li>Identifying when bagging or boosting is more appropriate</li>
                    <li>Implementing both techniques with scikit-learn</li>
                    <li>Understanding how each approach handles bias and variance</li>
                    <li>Evaluating performance differences between methods</li>
                </ul>
            </div>
            
            <div class="content-box">
                <h3>2. Gradient Boosting Model</h3>
                <p>Learn how gradient boosting models work and how to implement them effectively.</p>
                <ul>
                    <li>Understanding the mathematical principles of gradient boosting</li>
                    <li>Implementing gradient boosting with libraries like XGBoost</li>
                    <li>Tuning key hyperparameters for optimal performance</li>
                    <li>Preventing overfitting in gradient boosting models</li>
                    <li>Handling categorical features with gradient boosting</li>
                    <li>Interpreting gradient boosting outputs</li>
                </ul>
            </div>
            
            <div class="content-box">
                <h3>3. Feature Importances (default and permutation)</h3>
                <p>Learn how to interpret model outputs through feature importance metrics to understand what drives your predictions.</p>
                <ul>
                    <li>Understanding default feature importance calculations</li>
                    <li>Implementing permutation importance to measure feature impact</li>
                    <li>Comparing built-in vs. permutation importance methods</li>
                    <li>Using feature importances to guide feature selection</li>
                    <li>Visualizing feature importances effectively</li>
                    <li>Understanding the limitations of importance measures</li>
                </ul>
            </div>
        </section>

        <section>
            <h2>Guided Project</h2>
            <div class="content-box">
                <h3>Permutation and Boosting Guided Project</h3>
                <div class="video-container">
                    <iframe src="https://fast.wistia.net/embed/iframe/fm4wfnizfn" title="Permutation and Boosting Part One" allowtransparency="true" frameborder="0" scrolling="no" class="wistia_embed" name="wistia_embed" allowfullscreen mozallowfullscreen webkitallowfullscreen oallowfullscreen msallowfullscreen></iframe>
                </div>
                
                <h3>Part Two Video</h3>
                <div class="video-container">
                    <iframe src="https://fast.wistia.net/embed/iframe/c9r40cnw1d" title="Permutation and Boosting Part Two" allowtransparency="true" frameborder="0" scrolling="no" class="wistia_embed" name="wistia_embed" allowfullscreen mozallowfullscreen webkitallowfullscreen oallowfullscreen msallowfullscreen></iframe>
                </div>
                
                <p>In this guided project, you'll work through a complete workflow for feature permutation importance and gradient boosting. Using a real-world dataset, you'll learn to measure feature importance through permutation and implement XGBoost models to improve prediction performance.</p>
                
                <div class="resource-links">
                    <a href="https://github.com/bloominstituteoftechnology/DS-Unit-2-Applied-Modeling/tree/master/module3-permutation-boosting" class="resource-link" target="_blank" rel="noopener noreferrer">GitHub Repository</a>
                    <a href="#" class="resource-link" target="_blank" rel="noopener noreferrer">Guided Project Notebook (LS_DS_233.ipynb)</a>
                </div>
            </div>
        </section>

        <section>
            <h2>Module Assignment</h2>
            <div class="content-box">
                <h3>Feature Engineering and Model Selection for Your Portfolio Project</h3>
                <p>For this assignment, you'll continue working with your portfolio dataset from previous modules. You'll apply what you've learned to engineer meaningful features and select appropriate models for your specific problem.</p>
                
                <p><em>Note: There is no video for this assignment as you will be working with your own dataset and defining your own machine learning problem.</em></p>
                
                <h4>Assignment Notebook Name: LS_DS_233_assignment.ipynb</h4>
                <h4>Tasks:</h4>
                <ol>
                    <li>If you haven't completed assignment #1, please do so first.</li>
                    <li>Continue to clean and explore your data. Make exploratory visualizations.</li>
                    <li>Fit a model. Does it beat your baseline?</li>
                    <li>Try xgboost.</li>
                    <li>Get your model's permutation importances.</li>
                </ol>
                
                <div class="resource-links">
                    <a href="https://github.com/bloominstituteoftechnology/DS-Unit-2-Applied-Modeling/tree/master/module3-permutation-boosting" class="resource-link" target="_blank" rel="noopener noreferrer">Assignment GitHub Repository</a>
                </div>
            </div>
        </section>
        
        <section>
            <h2>Additional Resources</h2>
            <div class="content-box">
                <div class="resource-card">
                    <h3>Feature Engineering</h3>
                    <ul>
                        <li><a href="https://scikit-learn.org/stable/modules/preprocessing.html" target="_blank" rel="noopener noreferrer">Scikit-learn Preprocessing Guide</a></li>
                        <li><a href="https://www.kaggle.com/learn/feature-engineering" target="_blank" rel="noopener noreferrer">Kaggle Feature Engineering Course</a></li>
                    </ul>
                </div>
                
                <div class="resource-card">
                    <h3>Model Interpretation</h3>
                    <ul>
                        <li><a href="https://christophm.github.io/interpretable-ml-book/" target="_blank" rel="noopener noreferrer">Interpretable Machine Learning Book</a></li>
                        <li><a href="https://github.com/slundberg/shap" target="_blank" rel="noopener noreferrer">SHAP (SHapley Additive exPlanations)</a></li>
                    </ul>
                </div>
                
                <div class="resource-card">
                    <h3>Model Selection</h3>
                    <ul>
                        <li><a href="https://scikit-learn.org/stable/model_selection.html" target="_blank" rel="noopener noreferrer">Scikit-learn Model Selection Guide</a></li>
                        <li><a href="https://scikit-learn.org/stable/auto_examples/model_selection/plot_learning_curve.html" target="_blank" rel="noopener noreferrer">Learning Curves for Model Selection</a></li>
                    </ul>
                </div>
            </div>
        </section>
    </main>
</body>
</html> 