<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Module 4: Large Language Models</title>
    <link rel="stylesheet" href="../../assets/css/styles.css">
</head>
<body>
    <header>
        <nav>
            <div class="logo">Data Science Unit 4</div>
            <ul>
                <li><a href="../../index.html">Home</a></li>
                <li class="dropdown">
                    <a href="#" class="active">Modules</a>
                    <div class="dropdown-content">
                        <a href="../module1/index.html">Module 1: Recurrent Neural Networks and LSTM</a>
                        <a href="../module2/index.html">Module 2: Convolutional Neural Networks</a>
                        <a href="../module3/index.html">Module 3: OpenAI and ChatGPT</a>
                        <a href="../module4/index.html" class="active">Module 4: Large Language Models</a>
                    </div>
                </li>
                <li><a href="../../code-alongs/index.html">Code-Alongs</a></li>
                <li><a href="../../sprint-challenge/index.html">Sprint Challenge</a></li>
            </ul>
        </nav>
    </header>

    <main class="container">
        <section id="welcome">
            <h1>Module 4: Large Language Models</h1>
            <div class="content-box">
                <h2>Module Overview</h2>
                <p>This updated module takes you beyond interacting with existing LLM interfaces to building and customizing your own LLM-powered applications. Building on the foundation from Module 3, you'll learn to work directly with LLM APIs and local models to create sophisticated, context-aware conversational agents.</p>
                
                <p>You'll explore how to design and implement local LLM bots with customizable prompts and parameters, experiment with different model configurations, and tackle advanced challenges like implementing memory systems for more coherent conversations. This hands-on approach will give you practical experience in building production-ready LLM applications while understanding the technical considerations involved in deploying these powerful models.</p>
            </div>
        </section>

        <section id="learning-objectives">
            <div class="content-box">
                <h2>Learning Objectives</h2>
                <ul>
                    <li>Develop and customize local LLM bots with parameterized prompts and configurations</li>
                    <li>Implement memory systems and context management for enhanced conversational experiences</li>
                </ul>
            </div>
        </section>

        <section id="guided-project">
            <div class="content-box">
                <h2>Guided Project</h2>

                <p>This guided project focuses on hands-on LLM implementation and does not have traditional repository materials. For students interested in exploring additional technical background, you can review the <a href="https://github.com/bloominstituteoftechnology/DS-Unit-4-Sprint-3-Deep-Learning/tree/main/module4-time-series" target="_blank" rel="noopener">legacy Time Series Forecasting material</a> as supplementary content, though the current guided project and assignment are the primary focus.</p>

                <h3>Building a Chatbot with Persitent Memory</h3>

                <div class="video-container">
                    <iframe class="wistia_embed" title="Working with Large Language Models Video" src="https://fast.wistia.net/embed/iframe/ent2k5vi8x?seo=false&videoFoam=false" width="640" height="360" name="wistia_embed" allow="autoplay; fullscreen" loading="lazy"></iframe>
                </div>
            </div>
        </section>

        <section id="module-assignment">
            <div class="content-box">
                <h2>Module Assignment</h2>
                <p>This module features a hands-on implementation assignment that differs from our typical structured exercises.</p>
                
                <h3>Building an Advanced Local LLM Bot</h3>
                
                <h4>Objective:</h4>
                <p>The main goal of this assignment is to develop a local LLM bot with customizable prompts and parameters. As a stretch goal, you will implement a short-term memory model for the bot, allowing for more coherent and context-aware interactions.</p>
                
                <p>The instructions for this project are intentionally a bit vague. The purpose of this is for you to build something of your own design, which can present many challenges and more importantly, a portfolio-worthy project.</p>

                <h4>Prerequisites:</h4>
                <ul>
                    <li>Python programming experience</li>
                    <li>Basic understanding of machine learning, NLP, and LLMs</li>
                    <li>Access to an LLM API or local LLM setup</li>
                </ul>

                <h4>Steps:</h4>
                <ol>
                    <li><strong>Initial Setup</strong>
                        <ul>
                            <li>Set up a basic bot using a local LLM or an API service.</li>
                        </ul>
                    </li>
                    <li><strong>Experimentation</strong>
                        <ul>
                            <li>Experiment with various prompts and parameters to understand their impact on the bot's responses.</li>
                        </ul>
                    </li>
                    <li><strong>Refactoring</strong>
                        <ul>
                            <li>Refactor your bot into a function or class, making sure to parameterize the user_prompt.</li>
                        </ul>
                    </li>
                    <li><strong>Memory Module (Stretch Goal)</strong>
                        <ul>
                            <li>Implement a memory system for your bot. This can range from simply feeding back previous interactions to a more complex approach like a vector database for automatic relevant recall.</li>
                        </ul>
                    </li>
                    <li><strong>Evaluation</strong>
                        <ul>
                            <li>Evaluate the performance in terms of coherence, relevance, and context-awareness.</li>
                        </ul>
                    </li>
                    <li><strong>Documentation</strong>
                        <ul>
                            <li>Document your design choices, implementation details, and observations.</li>
                        </ul>
                    </li>
                    <li><strong>Peer Review (Stretch Goal)</strong>
                        <ul>
                            <li>Share your project for peer review, focusing on the bot's design, performance, and memory model.</li>
                        </ul>
                    </li>
                    <li><strong>Final Submission</strong>
                        <ul>
                            <li>Submit your code and documentation for evaluation.</li>
                        </ul>
                    </li>
                </ol>

                <h4>Evaluation Criteria:</h4>
                <ul>
                    <li>Quality of the design and implementation of the bot</li>
                    <li>Effectiveness of the parameterization and customization</li>
                    <li>Implementation and performance of the memory model (if attempted)</li>
                    <li>Peer review feedback (optional)</li>
                </ul>

                <h4>Resources:</h4>
                <ul>
                    <li><a href="https://platform.openai.com/docs/guides/text?api-mode=chat" target="_blank" rel="noopener">OpenAI API</a></li>
                    <li><a href="https://huggingface.co/models?pipeline_tag=text-generation&sort=trending" target="_blank" rel="noopener">Hugging Face LLMs</a></li>
                </ul>

                <h3>Assignment Solution Video</h3>
                <div class="video-container">
                    <iframe class="wistia_embed" title="LLM Bot Assignment Solution Video" src="https://fast.wistia.net/embed/iframe/8psbb0unf3?seo=false&videoFoam=false" width="640" height="360" name="wistia_embed" allow="autoplay; fullscreen" loading="lazy"></iframe>
                </div>
            </div>
        </section>

        <section id="additional-resources">
            <div class="content-box">
                <h2>Additional Resources</h2>
                <h3>LLM APIs and Platforms</h3>
                <ul>
                    <li><a href="https://platform.openai.com/docs/api-reference" target="_blank" rel="noopener">OpenAI API Reference</a></li>
                    <li><a href="https://huggingface.co/docs/transformers/main_classes/pipelines" target="_blank" rel="noopener">Hugging Face Transformers Pipelines</a></li>
                    <li><a href="https://docs.anthropic.com/claude/docs" target="_blank" rel="noopener">Anthropic Claude API Documentation</a></li>
                    <li><a href="https://ai.google.dev/docs" target="_blank" rel="noopener">Google AI Platform Documentation</a></li>
                </ul>
                <h3>Local LLM Implementation</h3>
                <ul>
                    <li><a href="https://ollama.ai/" target="_blank" rel="noopener">Ollama: Run LLMs Locally</a></li>
                    <li><a href="https://github.com/ggerganov/llama.cpp" target="_blank" rel="noopener">llama.cpp: Efficient LLM Inference</a></li>
                    <li><a href="https://docs.llamaindex.ai/en/stable/" target="_blank" rel="noopener">LlamaIndex: Data Framework for LLMs</a></li>
                    <li><a href="https://python.langchain.com/docs/get_started/introduction" target="_blank" rel="noopener">LangChain: Building Applications with LLMs</a></li>
                </ul>
                <h3>Memory and Context Management</h3>
                <ul>
                    <li><a href="https://github.com/chroma-core/chroma" target="_blank" rel="noopener">Chroma: Vector Database for LLMs</a></li>
                    <li><a href="https://www.pinecone.io/learn/vector-database/" target="_blank" rel="noopener">Pinecone: Vector Database Guide</a></li>
                    <li><a href="https://python.langchain.com/docs/how_to/chatbots_memory/" target="_blank" rel="noopener">LangChain: How to Add Memory to Chatbots</a></li>
                </ul>
            </div>
        </section>
    </main>
</body>
</html>
