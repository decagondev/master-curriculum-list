<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Module 3: AutoEncoders and Generative Models</title>
    <link rel="stylesheet" href="../../assets/css/styles.css">
</head>
<body>
    <header>
        <nav>
            <div class="logo">Data Science Unit 4</div>
            <ul>
                <li><a href="../../index.html">Home</a></li>
                <li class="dropdown">
                    <a href="#" class="active">Modules</a>
                    <div class="dropdown-content">
                        <a href="../module1/index.html">Module 1: Recurrent Neural Networks and LSTM</a>
                        <a href="../module2/index.html">Module 2: Convolutional Neural Networks</a>
                        <a href="../module3/index.html" class="active">Module 3: AutoEncoders and Generative Models</a>
                        <a href="../module4/index.html">Module 4: Time Series Forecasting</a>
                    </div>
                </li>
                <li><a href="../../code-alongs/index.html">Code-Alongs</a></li>
                <li><a href="../../sprint-challenge/index.html">Sprint Challenge</a></li>
            </ul>
        </nav>
    </header>

    <main class="container">
        <section id="welcome">
            <h1>Module 3: AutoEncoders and Generative Models</h1>
            <div class="card module3-accent">
                <h2>Module Overview</h2>
                <p>This module introduces AutoEncoders, a class of neural networks designed for unsupervised learning and dimensionality reduction. Unlike the previously covered neural network architectures that focused on prediction tasks, autoencoders learn to compress data into a lower-dimensional representation and then reconstruct it, extracting meaningful features in the process.</p>
                
                <p>You'll explore both standard autoencoders and their powerful extension, Variational AutoEncoders (VAEs), which enable generative capabilities. By the end of this module, you'll understand how to implement autoencoders for tasks like image reconstruction and information retrieval, opening up applications in recommendation systems, anomaly detection, and data generation.</p>
            </div>
        </section>

        <section id="learning-objectives">
            <h2>Learning Objectives</h2>
            <div class="content-box">
                <h3>1. Describe the components of an autoencoder</h3>
                <ul>
                    <li>Identify the encoder and decoder components of an autoencoder</li>
                    <li>Explain the purpose and architecture of the latent space</li>
                    <li>Distinguish between different types of autoencoders (standard, variational, etc.)</li>
                    <li>Understand the loss functions used in training autoencoders</li>
                </ul>
            </div>

            <div class="content-box">
                <h3>2. Apply an autoencoder to an image reconstruction problem</h3>
                <ul>
                    <li>Implement autoencoder models for image data using Keras</li>
                    <li>Train autoencoders to restore damaged or noisy images</li>
                    <li>Evaluate reconstruction quality using appropriate metrics</li>
                    <li>Compare different autoencoder architectures for image tasks</li>
                </ul>
            </div>

            <div class="content-box">
                <h3>3. Apply an autoencoder to a basic information retrieval problem, i.e. a "recommender system"</h3>
                <ul>
                    <li>Understand how latent representations can be used for information retrieval</li>
                    <li>Implement similarity measures in the latent space</li>
                    <li>Build a simple recommender system using autoencoder representations</li>
                    <li>Explore applications of autoencoders in semantic search and recommendation</li>
                </ul>
            </div>
        </section>

        <section id="guided-project">
            <h2>Guided Project</h2>
            <div class="content-box">
                <h3>AutoEncoders and Generative Models</h3>
                
                <div class="video-container">
                    <iframe class="wistia_embed" title="Sprint 15 AutoEncoders and Generative Models Video" src="https://fast.wistia.net/embed/iframe/3pxsensjdj" width="640" height="360" name="wistia_embed" allow="autoplay; fullscreen" loading="lazy"></iframe>
                </div>
                
                <div class="resource-section">
                    <h3 class="resource-section-title">Project Resources</h3>
                    <div class="resource-links">
                        <a href="https://github.com/bloominstituteoftechnology/DS-Unit-4-Sprint-3-Deep-Learning/tree/main/module3-autoencoders" class="resource-link" target="_blank" rel="noopener">GitHub Repo</a>
                    </div>
                </div>
                
                <h4>Guided Project File:</h4>
                <p>DS_433_Autoencoders_Lecture.ipynb</p>
            </div>
        </section>

        <section id="module-assignment">
            <h2>Module Assignment</h2>
            <div class="content-box">
                <p>Please read the assignment file in the GitHub repository for detailed instructions on completing your assignment tasks.</p>
                
                <h4>Assignment File:</h4>
                <p>DS_433_Autoencoders_Assignment.ipynb</p>

                <p>In this assignment, you will work with two types of autoencoders through two main exercises:</p>
                <ul>
                    <li><strong>Exercise 1:</strong> Apply autoencoders to restore damaged images
                        <ul>
                            <li>Load and prepare the MNIST dataset with artificial noise</li>
                            <li>Build a convolutional autoencoder model for image restoration</li>
                            <li>Train the model to reconstruct clean images from noisy inputs</li>
                            <li>Evaluate and visualize the restoration results</li>
                        </ul>
                    </li>
                    <li><strong>Exercise 2:</strong> Explore Variational Autoencoders (VAEs)
                        <ul>
                            <li>Understand the theory and architecture of VAEs</li>
                            <li>Implement a VAE model with encoder and decoder components</li>
                            <li>Explore the latent space and understand KL divergence loss</li>
                            <li>Generate new digit images by sampling from the learned latent space</li>
                            <li>Visualize label clusters in the latent space</li>
                        </ul>
                    </li>
                </ul>

                <h3>Assignment Solution Video</h3>
                <div class="video-container">
                    <iframe class="wistia_embed" title="DS_433_Autoencoders_Assignment_Solution Video" src="https://fast.wistia.net/embed/iframe/lhfheund6k" width="640" height="360" name="wistia_embed" allow="autoplay; fullscreen" loading="lazy"></iframe>
                </div>
            </div>
        </section>

        <section id="check-for-understanding">
            <h2>Check for Understanding</h2>
            <div class="content-box">
                <p>Complete the following items to test your understanding:</p>
                <ul>
                    <li>Explain the key differences between standard autoencoders and variational autoencoders</li>
                    <li>Describe how the bottleneck layer in an autoencoder helps with feature learning</li>
                    <li>Explain the purpose of the KL divergence loss in variational autoencoders</li>
                    <li>Discuss how autoencoders can be used for anomaly detection</li>
                    <li>Compare and contrast discriminative models and generative models in machine learning</li>
                </ul>
            </div>
        </section>

        <section id="additional-resources">
            <h2>Additional Resources</h2>
            <div class="content-box">
                <div class="resource-section">
                    <h3 class="resource-section-title">Learning Resources</h3>
                    <div class="resource-links">
                        <a href="https://arxiv.org/abs/1312.6114" class="resource-link" target="_blank" rel="noopener">Original VAE Paper: "Auto-Encoding Variational Bayes"</a>
                        <a href="https://lilianweng.github.io/posts/2018-08-12-vae/" class="resource-link" target="_blank" rel="noopener">From Autoencoder to Beta-VAE: Tutorial and Survey</a>
                        <a href="https://distill.pub/2016/deconv-checkerboard/" class="resource-link" target="_blank" rel="noopener">Deconvolution and Checkerboard Artifacts in Neural Networks</a>
                        <a href="https://www.jeremyjordan.me/autoencoders/" class="resource-link" target="_blank" rel="noopener">Introduction to Autoencoders</a>
                        <a href="https://www.tensorflow.org/tutorials/generative/cvae" class="resource-link" target="_blank" rel="noopener">TensorFlow Tutorial: Convolutional Variational Autoencoder</a>
                        <a href="https://thispersondoesnotexist.com/" class="resource-link" target="_blank" rel="noopener">This Person Does Not Exist (GAN-generated faces - open multiple tabs to see more)</a>
                    </div>
                </div>
            </div>
        </section>
    </main>
</body>
</html> 