<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Module 2: Convolutional Neural Networks</title>
    <link rel="stylesheet" href="../../assets/css/styles.css">
</head>
<body>
    <header>
        <nav>
            <div class="logo">Data Science Unit 4</div>
            <ul>
                <li><a href="../../index.html">Home</a></li>
                <li class="dropdown">
                    <a href="#" class="active">Modules</a>
                    <div class="dropdown-content">
                        <a href="../module1/index.html">Module 1: Recurrent Neural Networks and LSTM</a>
                        <a href="../module2/index.html" class="active">Module 2: Convolutional Neural Networks</a>
                        <a href="../module3/index.html">Module 3: AutoEncoders and Generative Models</a>
                        <a href="../module4/index.html">Module 4: Time Series Forecasting</a>
                    </div>
                </li>
                <li><a href="../../code-alongs/index.html">Code-Alongs</a></li>
                <li><a href="../../sprint-challenge/index.html">Sprint Challenge</a></li>
            </ul>
        </nav>
    </header>

    <main class="container">
        <section id="welcome">
            <h1>Module 2: Convolutional Neural Networks</h1>
            <div class="card module2-accent">
                <h2>Module Overview</h2>
                <p>This module introduces Convolutional Neural Networks (CNNs), a specialized type of neural network designed specifically for processing structured grid-like data such as images. While traditional neural networks struggle with the spatial structure of images, CNNs excel by implementing convolution operations that can automatically detect important features like edges, textures, and shapes.</p>
                
                <p>You'll learn the fundamental operations that make CNNs work—convolution and pooling—and understand how these operations allow the network to build increasingly complex representations of visual data. By the end of this module, you'll be able to implement your own CNN models from scratch and leverage the power of pre-trained networks through transfer learning, opening up possibilities for a wide range of computer vision applications.</p>
            </div>
        </section>

        <section id="learning-objectives">
            <h2>Learning Objectives</h2>
            <div class="content-box">
                <h3>1. Describe convolution and pooling</h3>
                <ul>
                    <li>Explain the mathematics behind convolutional operations</li>
                    <li>Understand how filters/kernels detect features in images</li>
                    <li>Describe the purpose and implementation of pooling layers</li>
                    <li>Identify the advantages of parameter sharing and sparse connectivity in CNNs</li>
                </ul>
            </div>

            <div class="content-box">
                <h3>2. Apply a convolutional neural network to an image classification task</h3>
                <ul>
                    <li>Build a CNN architecture using Keras for image classification</li>
                    <li>Implement data preprocessing techniques for image data</li>
                    <li>Configure appropriate hyperparameters for CNN training</li>
                    <li>Evaluate the performance of CNNs on image classification tasks</li>
                </ul>
            </div>

            <div class="content-box">
                <h3>3. Use a pre-trained convolution neural network for image classification</h3>
                <ul>
                    <li>Understand the concept and benefits of transfer learning</li>
                    <li>Utilize pre-trained models like ResNet, VGG, and Inception</li>
                    <li>Implement feature extraction and fine-tuning approaches</li>
                    <li>Compare the performance of custom models vs. pre-trained networks</li>
                </ul>
            </div>
        </section>

        <section id="guided-project">
            <h2>Guided Project</h2>
            <div class="content-box">
                <h3>Convolutional Neural Networks for Image Classification</h3>
                
                <div class="video-container">
                    <iframe class="wistia_embed" title="Sprint 15 Convolutional Neural Networks Video" src="https://fast.wistia.net/embed/iframe/4fc7u3v1cc" width="640" height="360" name="wistia_embed" allow="autoplay; fullscreen" loading="lazy"></iframe>
                </div>
                
                <div class="resource-section">
                    <h3 class="resource-section-title">Project Resources</h3>
                    <div class="resource-links">
                        <a href="https://github.com/bloominstituteoftechnology/DS-Unit-4-Sprint-3-Deep-Learning/tree/main/module2-convolutional-neural-networks" class="resource-link" target="_blank" rel="noopener">GitHub Repo</a>
                    </div>
                </div>
                
                <h4>Guided Project File:</h4>
                <p>DS_432_Convolutional_Neural_Networks_Lecture.ipynb</p>
            </div>
        </section>

        <section id="module-assignment">
            <h2>Module Assignment</h2>
            <div class="content-box">
                <p>Please read the assignment file in the GitHub repository for detailed instructions on completing your assignment tasks.</p>
                
                <h4>Assignment File:</h4>
                <p>DS_432_Convolution_Neural_Networks_Assignment.ipynb</p>

                <p>In this assignment, you will apply three different CNN approaches to a binary image classification problem classifying images of mountains and forests. Your tasks include:</p>
                <ul>
                    <li>Part 1: Implementing transfer learning with a pre-trained ResNet50 model</li>
                    <li>Part 2: Building and training a custom CNN model from scratch</li>
                    <li>Part 3: Implementing data augmentation techniques to improve model performance</li>
                    <li>Loading and preprocessing image data using Keras ImageDataGenerator</li>
                    <li>Using TensorBoard to monitor and compare model performance</li>
                    <li>Analyzing the effectiveness of different CNN architectures and training approaches</li>
                    <li>Working with limited training data (approximately 350 images per class)</li>
                </ul>

                <h3>Assignment Solution Video</h3>
                <div class="video-container">
                    <iframe class="wistia_embed" title="DS_432_Convolution_Neural_Networks_Assignment - Jupyter Notebook Video" src="https://fast.wistia.net/embed/iframe/l1sklrlzrd" width="640" height="360" name="wistia_embed" allow="autoplay; fullscreen" loading="lazy"></iframe>
                </div>
            </div>
        </section>

        <section id="check-for-understanding">
            <h2>Check for Understanding</h2>
            <div class="content-box">
                <p>Complete the following items to test your understanding:</p>
                <ul>
                    <li>Explain the difference between convolution and pooling operations in a CNN</li>
                    <li>Describe how filters in a CNN help detect features in images</li>
                    <li>Compare and contrast transfer learning and training a CNN from scratch</li>
                    <li>Explain how data augmentation can improve model performance with limited data</li>
                    <li>Describe the architecture of a typical CNN and the purpose of each layer type</li>
                </ul>
            </div>
        </section>

        <section id="additional-resources">
            <h2>Additional Resources</h2>
            <div class="content-box">
                <div class="resource-section">
                    <h3 class="resource-section-title">Learning Resources</h3>
                    <div class="resource-links">
                        <a href="https://keras.io/api/applications/" class="resource-link" target="_blank" rel="noopener">Keras Applications: Pre-trained Models</a>
                        <a href="https://cs231n.github.io/convolutional-networks/" class="resource-link" target="_blank" rel="noopener">Stanford CS231n: Convolutional Neural Networks</a>
                        <a href="https://arxiv.org/abs/1512.03385" class="resource-link" target="_blank" rel="noopener">Deep Residual Learning for Image Recognition (ResNet Paper)</a>
                        <a href="https://distill.pub/2017/feature-visualization/" class="resource-link" target="_blank" rel="noopener">Feature Visualization: How Neural Networks Build Up Their Understanding of Images</a>
                        <a href="https://www.tensorflow.org/tutorials/images/data_augmentation" class="resource-link" target="_blank" rel="noopener">TensorFlow: Image Data Augmentation</a>
                        <a href="https://pjreddie.com/darknet/yolo/" class="resource-link" target="_blank" rel="noopener">YOLO: Real-Time Object Detection</a>
                        <a href="https://cocodataset.org/" class="resource-link" target="_blank" rel="noopener">COCO: Common Objects in Context Dataset</a>
                    </div>
                </div>
            </div>
        </section>
    </main>
</body>
</html>
