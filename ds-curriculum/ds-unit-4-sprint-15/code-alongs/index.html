<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Code-Alongs - DS Unit 4 Sprint 15</title>
    <link rel="stylesheet" href="../assets/css/styles.css">
</head>
<body>
    <header>
        <nav>
            <div class="logo">Data Science Unit 4</div>
            <ul>
                <li><a href="../index.html">Home</a></li>
                <li class="dropdown">
                    <a href="#">Modules</a>
                    <div class="dropdown-content">
                        <a href="../modules/module1/index.html">Module 1: Recurrent Neural Networks and LSTM</a>
                        <a href="../modules/module2/index.html">Module 2: Convolutional Neural Networks</a>
                        <a href="../modules/module3/index.html">Module 3: OpenAI and ChatGPT</a>
                        <a href="../modules/module4/index.html">Module 4: Large Language Models</a>
                    </div>
                </li>
                <li><a href="index.html" class="active">Code-Alongs</a></li>
                <li><a href="../sprint-challenge/index.html">Sprint Challenge</a></li>
            </ul>
        </nav>
    </header>

    <main class="container">
        <h1>Code-Alongs - DS Unit 4 Sprint 15</h1>

        <section id="preparation">
            <h2>Preparation for Code-Alongs</h2>
            <div class="content-box">
                <h3>What is a Code-Along?</h3>
                <div class="video-container">
                    <iframe src="https://fast.wistia.net/embed/iframe/hbcdzlz9ga" frameborder="0" allowfullscreen></iframe>
                </div>
                <p>Code-Alongs are live experiences taught by our expert instructors designed to prepare you for concepts found in the sprint challenges. Code-Alongs are your opportunity to work on complex job-ready problems in a live and engaging environment.</p>
                <p>Code-Alongs are live classes 50 minutes in length designed to offer deeper insights into learning your core competencies and are offered seven days a week in the morning, afternoon, and evening.</p>
                <p>Because Code-Alongs delve deeper into a core competency, you will need to come to class prepared to have the best experience.</p>
                
                <h3>Ideal Code-Along Preparation Checklist:</h3>
                <ul>
                    <li>Did you review the core competencies before coming to class?</li>
                    <li>Did you watch the guided projects before coming to class?</li>
                    <li>Did you take the checks for understanding before coming to class?</li>
                    <li>Did you finish your module projects before coming to class?</li>
                </ul>
            </div>
        </section>

        <section id="code-along-sessions">
            <h2>Code-Along Sessions</h2>
            
            <div class="module-card code-along-accent">
                <h3>Code-Along 1</h3>
                <h4>LSTM Text Generation</h4>
                <p>In this code-along, you'll build an LSTM-based text generation model that learns patterns from input text and generates new content. You'll implement a neural network with bidirectional LSTM layers to predict the next words given a seed phrase, creating an AI system that can produce creative text continuations.</p>
                <div class="resource-section">
                    <h3 class="resource-section-title">GitHub Resources</h3>
                    <div class="resource-links">
                        <a href="https://github.com/bloominstituteoftechnology/ds_code_along_unit_4/blob/main/DS_15.1_LSTM_Text_Generation/starter_notebook/15_1_LSTM_Text_Generation_Starter.ipynb" class="resource-link" target="_blank" rel="noopener">Starter Notebook</a>
                        <a href="https://github.com/bloominstituteoftechnology/ds_code_along_unit_4/blob/main/DS_15.1_LSTM_Text_Generation/solution_notebook/15_1_LSTM_Text_Generation_Solution.ipynb" class="resource-link" target="_blank" rel="noopener">Solution Notebook</a>
                    </div>
                </div>
            </div>

            <div class="module-card code-along-accent">
                <h3>Code-Along 2</h3>
                <h4>Variational AutoEncoders</h4>
                <p>In this code-along, you'll implement a Variational AutoEncoder (VAE) that can generate realistic digit images from random noise. You'll build both encoder and decoder networks, implement the critical reparameterization trick, and train the model to learn a continuous latent space representation of handwritten digits.</p>
                <div class="resource-section">
                    <h3 class="resource-section-title">GitHub Resources</h3>
                    <div class="resource-links">
                        <a href="https://github.com/bloominstituteoftechnology/ds_code_along_unit_4/blob/main/DS_15.2_Variational_AutoEncoders/starter_notebook/15_2_Variational_AutoEncoders_Starter.ipynb" class="resource-link" target="_blank" rel="noopener">Starter Notebook</a>
                        <a href="https://github.com/bloominstituteoftechnology/ds_code_along_unit_4/blob/main/DS_15.2_Variational_AutoEncoders/solution_notebook/15_2_Variational_AutoEncoders_Solution.ipynb" class="resource-link" target="_blank" rel="noopener">Solution Notebook</a>
                    </div>
                </div>
            </div>
        </section>

        <section id="additional-resources">
            <h2>Additional Resources</h2>
            <div class="content-box">
                <div class="resource-section">
                    <h3 class="resource-section-title">LSTM Text Generation Resources</h3>
                    <div class="resource-links">
                        <a href="https://www.tensorflow.org/tutorials/text/text_generation" class="resource-link" target="_blank" rel="noopener">TensorFlow: Text Generation with RNN</a>
                        <a href="https://colah.github.io/posts/2015-08-Understanding-LSTMs/" class="resource-link" target="_blank" rel="noopener">Understanding LSTM Networks</a>
                        <a href="https://karpathy.github.io/2015/05/21/rnn-effectiveness/" class="resource-link" target="_blank" rel="noopener">The Unreasonable Effectiveness of RNNs</a>
                        <a href="https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-recurrent-neural-networks" class="resource-link" target="_blank" rel="noopener">Stanford CS230: RNN Cheatsheet</a>
                    </div>
                </div>
                
                <div class="resource-section">
                    <h3 class="resource-section-title">Variational AutoEncoder Resources</h3>
                    <div class="resource-links">
                        <a href="https://arxiv.org/abs/1312.6114" class="resource-link" target="_blank" rel="noopener">Original VAE Paper: "Auto-Encoding Variational Bayes"</a>
                        <a href="https://lilianweng.github.io/posts/2018-08-12-vae/" class="resource-link" target="_blank" rel="noopener">From Autoencoder to Beta-VAE: Tutorial</a>
                        <a href="https://distill.pub/2016/deconv-checkerboard/" class="resource-link" target="_blank" rel="noopener">Deconvolution and Checkerboard Artifacts</a>
                        <a href="https://www.jeremyjordan.me/autoencoders/" class="resource-link" target="_blank" rel="noopener">Introduction to Autoencoders</a>
                        <a href="https://www.tensorflow.org/tutorials/generative/cvae" class="resource-link" target="_blank" rel="noopener">TensorFlow: Convolutional VAE</a>
                    </div>
                </div>
            </div>
        </section>
    </main>
</body>
</html> 