<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>DS Unit 4 Sprint 15: Major Neural Network Architectures</title>
    <link rel="stylesheet" href="assets/css/styles.css">
</head>
<body>
    <header>
        <nav>
            <div class="logo">Data Science Unit 4</div>
            <ul>
                <li><a href="index.html" class="active">Home</a></li>
                <li class="dropdown">
                    <a href="#">Modules</a>
                    <div class="dropdown-content">
                        <a href="modules/module1/index.html">Module 1: Recurrent Neural Networks and LSTM</a>
                        <a href="modules/module2/index.html">Module 2: Convolutional Neural Networks</a>
                        <a href="modules/module3/index.html">Module 3: OpenAI and ChatGPT</a>
                        <a href="modules/module4/index.html">Module 4: Large Language Models</a>
                    </div>
                </li>
                <li><a href="code-alongs/index.html">Code-Alongs</a></li>
                <li><a href="sprint-challenge/index.html">Sprint Challenge</a></li>
            </ul>
        </nav>
    </header>

    <main class="container">
        <section id="welcome">
            <h1>DS Unit 4 Sprint 15: Major Neural Network Architectures</h1>
            <div class="content-box">
                <h2>Welcome to Sprint 15</h2>
                <p>Now that you've learned the foundations of Neural Networks, it's time to go deep! Of course, all "deep learning" really means is "there's at least some hidden layers" - but there's a great deal of variety both in the layered architecture and the behavior of individual "neurons" in the network.</p>
                
                <p>We'll study a few of the most effective recent innovations in neural networks and deep learning and think a bit about what the future may hold. Is deep learning the path to artificial general intelligence? Probably not - but LLMs might get us part way there!</p>
            </div>
        </section>

        <section id="sprint-overview">
            <div class="content-box">
                <h2>Sprint Modules</h2>
                <p>This sprint explores specialized neural network architectures that power today's most advanced AI applications in computer vision, natural language processing, and time series forecasting:</p>
                
                <div class="module-cards">
                    <div class="module-card module1-accent">
                        <h3>Module 1</h3>
                        <h4>Recurrent Neural Networks and LSTM</h4>
                        <p>Traditional neural networks are feedforward, but recurrent neural networks introduce cycles that act as memory. This makes them ideal for sequential data like natural language, time series, and other contexts where order matters. Learn how LSTMs overcome the vanishing gradient problem.</p>
                        <a href="modules/module1/index.html" class="btn">View Module</a>
                    </div>
                    
                    <div class="module-card module2-accent">
                        <h3>Module 2</h3>
                        <h4>Convolutional Neural Networks</h4>
                        <p>CNNs draw from biological inspiration, using neuron connectivity patterns that resemble the brain's visual fields. These models excel at image recognition and classification, often achieving human-level performance with minimal preprocessing.</p>
                        <a href="modules/module2/index.html" class="btn">View Module</a>
                    </div>
                    
                    <div class="module-card module3-accent">
                        <h3>Module 3</h3>
                        <h4>OpenAI and ChatGPT</h4>
                        <p>Explore ChatGPT and transformer-based models that demonstrate AI's ability to understand and generate human-like text. Learn about the architecture, applications, and ethical considerations of these powerful language models.</p>
                        <a href="modules/module3/index.html" class="btn">View Module</a>
                    </div>
                    
                    <div class="module-card module4-accent">
                        <h3>Module 4</h3>
                        <h4>Large Language Models</h4>
                        <p>Work with LLMs through the OpenAI API and SDK for text generation and summarization. Learn to customize outputs using parameters and set up local LLMs for specialized applications like chatbots.</p>
                        <a href="modules/module4/index.html" class="btn">View Module</a>
                    </div>
                </div>
            </div>
        </section>

        <section id="resources">
            <div class="content-box">
                <h2>Sprint Resources</h2>
                <div class="resource-section">
                    <h3 class="resource-section-title">Primary Resources</h3>
                    <div class="resource-links">
                        <a href="code-alongs/index.html" class="resource-link">Code-Along Sessions</a>
                        <a href="sprint-challenge/index.html" class="resource-link">Sprint Challenge</a>
                    </div>
                </div>
                
                <div class="resource-section">
                    <h3 class="resource-section-title">Sequential Models and Time Series</h3>
                    <ul>
                        <li><a href="https://colah.github.io/posts/2015-08-Understanding-LSTMs/" target="_blank" rel="noopener">Understanding LSTM Networks</a></li>
                        <li><a href="https://distill.pub/2016/augmented-rnns/" target="_blank" rel="noopener">Distill: Attention and Augmented RNNs</a></li>
                        <li><a href="https://www.tensorflow.org/tutorials/text/text_generation" target="_blank" rel="noopener">TensorFlow: Text Generation with RNN</a></li>
                        <li><a href="https://karpathy.github.io/2015/05/21/rnn-effectiveness/" target="_blank" rel="noopener">The Unreasonable Effectiveness of RNNs</a></li>
                    </ul>
                </div>

                <div class="resource-section">
                    <h3 class="resource-section-title">Computer Vision and CNNs</h3>
                    <ul>
                        <li><a href="https://cs231n.github.io/convolutional-networks/" target="_blank" rel="noopener">Stanford CS231n: Convolutional Neural Networks</a></li>
                        <li><a href="https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53" target="_blank" rel="noopener">A Comprehensive Guide to CNNs</a></li>
                        <li><a href="https://distill.pub/2017/feature-visualization/" target="_blank" rel="noopener">Feature Visualization in Neural Networks</a></li>
                        <li><a href="https://keras.io/api/applications/" target="_blank" rel="noopener">Keras Applications: Pre-trained Models</a></li>
                    </ul>
                </div>

                <div class="resource-section">
                    <h3 class="resource-section-title">Large Language Models and OpenAI</h3>
                    <ul>
                        <li><a href="https://platform.openai.com/docs" target="_blank" rel="noopener">OpenAI API Documentation</a></li>
                        <li><a href="https://arxiv.org/abs/1706.03762" target="_blank" rel="noopener">Attention Is All You Need (Transformer Paper)</a></li>
                        <li><a href="https://huggingface.co/transformers/" target="_blank" rel="noopener">Hugging Face Transformers</a></li>
                        <li><a href="https://github.com/ggerganov/llama.cpp" target="_blank" rel="noopener">llama.cpp: Local LLM Inference</a></li>
                    </ul>
                </div>

                <div class="resource-section">
                    <h3 class="resource-section-title">Advanced Deep Learning</h3>
                    <ul>
                        <li><a href="https://www.deeplearningbook.org/" target="_blank" rel="noopener">Deep Learning Book</a></li>
                        <li><a href="https://playground.tensorflow.org/" target="_blank" rel="noopener">TensorFlow Playground</a></li>
                        <li><a href="https://blog.keras.io/building-autoencoders-in-keras.html" target="_blank" rel="noopener">Building Autoencoders in Keras</a></li>
                        <li><a href="https://distill.pub/" target="_blank" rel="noopener">Distill: Interactive ML Articles</a></li>
                    </ul>
                </div>
            </div>
        </section>
    </main>
</body>
</html>
