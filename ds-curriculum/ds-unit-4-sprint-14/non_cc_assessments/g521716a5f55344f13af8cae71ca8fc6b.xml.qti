<?xml version="1.0" encoding="UTF-8"?>
<questestinterop xmlns="http://www.imsglobal.org/xsd/ims_qtiasiv1p2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.imsglobal.org/xsd/ims_qtiasiv1p2 http://www.imsglobal.org/xsd/ims_qtiasiv1p2p1.xsd">
  <objectbank ident="g521716a5f55344f13af8cae71ca8fc6b">
    <qtimetadata>
      <qtimetadatafield>
        <fieldlabel>bank_title</fieldlabel>
        <fieldentry>Module 4 - Deploy</fieldentry>
      </qtimetadatafield>
      <qtimetadatafield>
        <fieldlabel>bank_context_uuid</fieldlabel>
        <fieldentry>5aO0cGnEEjQz7xiNQlXLIS3lNcPBsPI32ReGFzHr</fieldentry>
      </qtimetadatafield>
    </qtimetadata>
    <item ident="gc9aaf3cc8ce7656fc7ef24b0debcc50c" title="606cf9c2-1d4c-4f95-9100-849e27a63d4d">
      <itemmetadata>
        <qtimetadata>
          <qtimetadatafield>
            <fieldlabel>question_type</fieldlabel>
            <fieldentry>multiple_choice_question</fieldentry>
          </qtimetadatafield>
          <qtimetadatafield>
            <fieldlabel>points_possible</fieldlabel>
            <fieldentry>1.0</fieldentry>
          </qtimetadatafield>
          <qtimetadatafield>
            <fieldlabel>original_answer_ids</fieldlabel>
            <fieldentry>4986,9807,9392,4158</fieldentry>
          </qtimetadatafield>
        </qtimetadata>
      </itemmetadata>
      <presentation>
        <material>
          <mattext texttype="text/html">&lt;div&gt;In which sequential Keras model method do you specify Callbacks such as EarlyStopping?&lt;/div&gt;</mattext>
        </material>
        <response_lid ident="response1" rcardinality="Single">
          <render_choice>
            <response_label ident="4986">
              <material>
                <mattext texttype="text/plain">model.fit()</mattext>
              </material>
            </response_label>
            <response_label ident="9807">
              <material>
                <mattext texttype="text/plain">model.add()</mattext>
              </material>
            </response_label>
            <response_label ident="9392">
              <material>
                <mattext texttype="text/plain">model.compile()</mattext>
              </material>
            </response_label>
            <response_label ident="4158">
              <material>
                <mattext texttype="text/plain">model.evaluate()</mattext>
              </material>
            </response_label>
          </render_choice>
        </response_lid>
      </presentation>
      <resprocessing>
        <outcomes>
          <decvar maxvalue="100" minvalue="0" varname="SCORE" vartype="Decimal"/>
        </outcomes>
        <respcondition continue="No">
          <conditionvar>
            <varequal respident="response1">4986</varequal>
          </conditionvar>
          <setvar action="Set" varname="SCORE">100</setvar>
        </respcondition>
      </resprocessing>
    </item>
    <item ident="g7620de4737068b93bcec77328d580b6e" title="6614b87f-7b68-470a-a763-cb6896323757">
      <itemmetadata>
        <qtimetadata>
          <qtimetadatafield>
            <fieldlabel>question_type</fieldlabel>
            <fieldentry>multiple_choice_question</fieldentry>
          </qtimetadatafield>
          <qtimetadatafield>
            <fieldlabel>points_possible</fieldlabel>
            <fieldentry>1.0</fieldentry>
          </qtimetadatafield>
          <qtimetadatafield>
            <fieldlabel>original_answer_ids</fieldlabel>
            <fieldentry>5118,7481,3520</fieldentry>
          </qtimetadatafield>
        </qtimetadata>
      </itemmetadata>
      <presentation>
        <material>
          <mattext texttype="text/html">&lt;div&gt;&lt;span&gt;Based on your project today, how confident are you that you could &lt;/span&gt;&lt;em&gt;&lt;span&gt;&lt;span style="color: #e03e2d;"&gt;describe and implement regulation strategies including early stopping, dropout, weight decay and weight constraint&lt;/span&gt;&lt;/span&gt;&lt;/em&gt;&lt;span&gt; in a project or interview tomorrow? &lt;/span&gt;&lt;br&gt;&lt;br&gt;&lt;span&gt;Answer on a scale of 1 to 3 where 1 = not yet, 2 = confident, and 3 = I could go above and beyond.&lt;/span&gt;&lt;/div&gt;</mattext>
        </material>
        <response_lid ident="response1" rcardinality="Single">
          <render_choice>
            <response_label ident="5118">
              <material>
                <mattext texttype="text/plain">1</mattext>
              </material>
            </response_label>
            <response_label ident="7481">
              <material>
                <mattext texttype="text/plain">2</mattext>
              </material>
            </response_label>
            <response_label ident="3520">
              <material>
                <mattext texttype="text/plain">3</mattext>
              </material>
            </response_label>
          </render_choice>
        </response_lid>
      </presentation>
      <resprocessing>
        <outcomes>
          <decvar maxvalue="100" minvalue="0" varname="SCORE" vartype="Decimal"/>
        </outcomes>
        <respcondition continue="No">
          <conditionvar>
            <varequal respident="response1">7481</varequal>
          </conditionvar>
          <setvar action="Set" varname="SCORE">100</setvar>
        </respcondition>
      </resprocessing>
    </item>
    <item ident="gf15662d1c4e642866f419e7dac40c1c5" title="71bb5df3-53a5-4fe3-9e23-0e24520c384d">
      <itemmetadata>
        <qtimetadata>
          <qtimetadatafield>
            <fieldlabel>question_type</fieldlabel>
            <fieldentry>multiple_choice_question</fieldentry>
          </qtimetadatafield>
          <qtimetadatafield>
            <fieldlabel>points_possible</fieldlabel>
            <fieldentry>1.0</fieldentry>
          </qtimetadatafield>
          <qtimetadatafield>
            <fieldlabel>original_answer_ids</fieldlabel>
            <fieldentry>4291,1329,481,3352</fieldentry>
          </qtimetadatafield>
        </qtimetadata>
      </itemmetadata>
      <presentation>
        <material>
          <mattext texttype="text/html">&lt;div&gt;Why should we avoid using too high of a dropout probability in our neural network?&lt;/div&gt;</mattext>
        </material>
        <response_lid ident="response1" rcardinality="Single">
          <render_choice>
            <response_label ident="4291">
              <material>
                <mattext texttype="text/plain">If there are not enough neurons remaining after dropout, the model will not be able to learn well.</mattext>
              </material>
            </response_label>
            <response_label ident="1329">
              <material>
                <mattext texttype="text/plain">The model will be too complex and will overfit the data.</mattext>
              </material>
            </response_label>
            <response_label ident="481">
              <material>
                <mattext texttype="text/plain">The model will take too long to converge on a solution.</mattext>
              </material>
            </response_label>
            <response_label ident="3352">
              <material>
                <mattext texttype="text/plain">A high probability means that only a few neurons are dropped, resulting in little to no effect on the model results.</mattext>
              </material>
            </response_label>
          </render_choice>
        </response_lid>
      </presentation>
      <resprocessing>
        <outcomes>
          <decvar maxvalue="100" minvalue="0" varname="SCORE" vartype="Decimal"/>
        </outcomes>
        <respcondition continue="Yes">
          <conditionvar>
            <other/>
          </conditionvar>
          <displayfeedback feedbacktype="Response" linkrefid="general_fb"/>
        </respcondition>
        <respcondition continue="Yes">
          <conditionvar>
            <varequal respident="response1">1329</varequal>
          </conditionvar>
          <displayfeedback feedbacktype="Response" linkrefid="1329_fb"/>
        </respcondition>
        <respcondition continue="Yes">
          <conditionvar>
            <varequal respident="response1">481</varequal>
          </conditionvar>
          <displayfeedback feedbacktype="Response" linkrefid="481_fb"/>
        </respcondition>
        <respcondition continue="Yes">
          <conditionvar>
            <varequal respident="response1">3352</varequal>
          </conditionvar>
          <displayfeedback feedbacktype="Response" linkrefid="3352_fb"/>
        </respcondition>
        <respcondition continue="No">
          <conditionvar>
            <varequal respident="response1">4291</varequal>
          </conditionvar>
          <setvar action="Set" varname="SCORE">100</setvar>
        </respcondition>
      </resprocessing>
      <itemfeedback ident="general_fb">
        <flow_mat>
          <material>
            <mattext texttype="text/plain">Usually a dropout rate between 20-50% has good results, where 20% is a good starting point.</mattext>
          </material>
        </flow_mat>
      </itemfeedback>
      <itemfeedback ident="1329_fb">
        <flow_mat>
          <material>
            <mattext texttype="text/plain">A high dropout probability results in a less complex model that might under-fit instead of over-fit.</mattext>
          </material>
        </flow_mat>
      </itemfeedback>
      <itemfeedback ident="481_fb">
        <flow_mat>
          <material>
            <mattext texttype="text/plain">A high dropout probability will decrease the training time.</mattext>
          </material>
        </flow_mat>
      </itemfeedback>
      <itemfeedback ident="3352_fb">
        <flow_mat>
          <material>
            <mattext texttype="text/plain">A high dropout probability results in fewer neurons remaining in the dropout layer.</mattext>
          </material>
        </flow_mat>
      </itemfeedback>
    </item>
    <item ident="gba5108b0056d176083f3c06087b04ca9" title="7a709941-7387-4b1e-bd78-c295e4296feb">
      <itemmetadata>
        <qtimetadata>
          <qtimetadatafield>
            <fieldlabel>question_type</fieldlabel>
            <fieldentry>multiple_choice_question</fieldentry>
          </qtimetadatafield>
          <qtimetadatafield>
            <fieldlabel>points_possible</fieldlabel>
            <fieldentry>1.0</fieldentry>
          </qtimetadatafield>
          <qtimetadatafield>
            <fieldlabel>original_answer_ids</fieldlabel>
            <fieldentry>6096,4090,8060,3005</fieldentry>
          </qtimetadatafield>
        </qtimetadata>
      </itemmetadata>
      <presentation>
        <material>
          <mattext texttype="text/html">&lt;div&gt;Which of the following choices will save both the weights and architecture of a model and then load the model after saving? Assume the model has been created and trained as &lt;code&gt;model&lt;/code&gt;.&lt;/div&gt;</mattext>
        </material>
        <response_lid ident="response1" rcardinality="Single">
          <render_choice>
            <response_label ident="6096">
              <material>
                <mattext texttype="text/html">&lt;pre&gt;&lt;code&gt;model.save("my_model")
new_model = tf.keras.models.load_model("my_model")&lt;/code&gt;&lt;/pre&gt;</mattext>
              </material>
            </response_label>
            <response_label ident="4090">
              <material>
                <mattext texttype="text/html">&lt;pre&gt;&lt;code&gt;cpoint = tf.keras.callbacks.ModelCheckpoint("weights_best.h5", verbose=1, save_weights_only=True)
model.load_weights("weights_best.h5")&lt;/code&gt;&lt;/pre&gt;</mattext>
              </material>
            </response_label>
            <response_label ident="8060">
              <material>
                <mattext texttype="text/html">&lt;code&gt;new_model = tf.keras.models.load_model("my_model")&lt;/code&gt;</mattext>
              </material>
            </response_label>
            <response_label ident="3005">
              <material>
                <mattext texttype="text/html">We can't save a model architecture, only the model weights.</mattext>
              </material>
            </response_label>
          </render_choice>
        </response_lid>
      </presentation>
      <resprocessing>
        <outcomes>
          <decvar maxvalue="100" minvalue="0" varname="SCORE" vartype="Decimal"/>
        </outcomes>
        <respcondition continue="Yes">
          <conditionvar>
            <other/>
          </conditionvar>
          <displayfeedback feedbacktype="Response" linkrefid="general_fb"/>
        </respcondition>
        <respcondition continue="Yes">
          <conditionvar>
            <varequal respident="response1">4090</varequal>
          </conditionvar>
          <displayfeedback feedbacktype="Response" linkrefid="4090_fb"/>
        </respcondition>
        <respcondition continue="Yes">
          <conditionvar>
            <varequal respident="response1">8060</varequal>
          </conditionvar>
          <displayfeedback feedbacktype="Response" linkrefid="8060_fb"/>
        </respcondition>
        <respcondition continue="Yes">
          <conditionvar>
            <varequal respident="response1">3005</varequal>
          </conditionvar>
          <displayfeedback feedbacktype="Response" linkrefid="3005_fb"/>
        </respcondition>
        <respcondition continue="No">
          <conditionvar>
            <varequal respident="response1">6096</varequal>
          </conditionvar>
          <setvar action="Set" varname="SCORE">100</setvar>
        </respcondition>
      </resprocessing>
      <itemfeedback ident="general_fb">
        <flow_mat>
          <material>
            <mattext texttype="text/plain">With the `keras.model.load_model` module, it's easy to load both the weight and architecture of a previously created and trained model.</mattext>
          </material>
        </flow_mat>
      </itemfeedback>
      <itemfeedback ident="4090_fb">
        <flow_mat>
          <material>
            <mattext texttype="text/plain">This will only save the model weights; we also want the architecture.</mattext>
          </material>
        </flow_mat>
      </itemfeedback>
      <itemfeedback ident="8060_fb">
        <flow_mat>
          <material>
            <mattext texttype="text/plain">We need to first save the model weight and architecture before loading the model.</mattext>
          </material>
        </flow_mat>
      </itemfeedback>
      <itemfeedback ident="3005_fb">
        <flow_mat>
          <material>
            <mattext texttype="text/plain">We can save a model architecture! This saves time when setting up a complex model that you might want to run on a another data set.</mattext>
          </material>
        </flow_mat>
      </itemfeedback>
    </item>
    <item ident="gebc99d3d6257206d6c485060ab2fe9e4" title="8450f20b-ec09-4d4e-86c4-5b4db030e739">
      <itemmetadata>
        <qtimetadata>
          <qtimetadatafield>
            <fieldlabel>question_type</fieldlabel>
            <fieldentry>multiple_choice_question</fieldentry>
          </qtimetadatafield>
          <qtimetadatafield>
            <fieldlabel>points_possible</fieldlabel>
            <fieldentry>1.0</fieldentry>
          </qtimetadatafield>
          <qtimetadatafield>
            <fieldlabel>original_answer_ids</fieldlabel>
            <fieldentry>3440,6233,3206,2998</fieldentry>
          </qtimetadatafield>
        </qtimetadata>
      </itemmetadata>
      <presentation>
        <material>
          <mattext texttype="text/html">&lt;div&gt;Which of the following regularization techniques determines which neurons receive data from the previous layer?&lt;/div&gt;</mattext>
        </material>
        <response_lid ident="response1" rcardinality="Single">
          <render_choice>
            <response_label ident="3440">
              <material>
                <mattext texttype="text/plain">dropout</mattext>
              </material>
            </response_label>
            <response_label ident="6233">
              <material>
                <mattext texttype="text/plain">weight decay</mattext>
              </material>
            </response_label>
            <response_label ident="3206">
              <material>
                <mattext texttype="text/plain">early stopping</mattext>
              </material>
            </response_label>
            <response_label ident="2998">
              <material>
                <mattext texttype="text/plain">weight constraint</mattext>
              </material>
            </response_label>
          </render_choice>
        </response_lid>
      </presentation>
      <resprocessing>
        <outcomes>
          <decvar maxvalue="100" minvalue="0" varname="SCORE" vartype="Decimal"/>
        </outcomes>
        <respcondition continue="No">
          <conditionvar>
            <varequal respident="response1">3440</varequal>
          </conditionvar>
          <setvar action="Set" varname="SCORE">100</setvar>
        </respcondition>
      </resprocessing>
    </item>
    <item ident="g3ae1db7521797fd4f1688eb45719ba30" title="8eea7f76-b6a0-4f18-8bf6-47c7c50757fd">
      <itemmetadata>
        <qtimetadata>
          <qtimetadatafield>
            <fieldlabel>question_type</fieldlabel>
            <fieldentry>multiple_choice_question</fieldentry>
          </qtimetadatafield>
          <qtimetadatafield>
            <fieldlabel>points_possible</fieldlabel>
            <fieldentry>1.0</fieldentry>
          </qtimetadatafield>
          <qtimetadatafield>
            <fieldlabel>original_answer_ids</fieldlabel>
            <fieldentry>2808,5732,3545</fieldentry>
          </qtimetadatafield>
        </qtimetadata>
      </itemmetadata>
      <presentation>
        <material>
          <mattext texttype="text/html">&lt;div&gt;&lt;span&gt;Based on your project today, how confident are you that you could &lt;/span&gt;&lt;em&gt;&lt;span&gt;&lt;span style="color: #e03e2d;"&gt;export a keras model and load it into a lightweight web application&lt;/span&gt;&lt;/span&gt;&lt;/em&gt;&lt;span&gt; in a project or interview tomorrow? &lt;/span&gt;&lt;br&gt;&lt;br&gt;&lt;span&gt;Answer on a scale of 1 to 3 where 1 = not yet, 2 = confident, and 3 = I could go above and beyond.&lt;/span&gt;&lt;/div&gt;</mattext>
        </material>
        <response_lid ident="response1" rcardinality="Single">
          <render_choice>
            <response_label ident="2808">
              <material>
                <mattext texttype="text/plain">1</mattext>
              </material>
            </response_label>
            <response_label ident="5732">
              <material>
                <mattext texttype="text/plain">2</mattext>
              </material>
            </response_label>
            <response_label ident="3545">
              <material>
                <mattext texttype="text/plain">3</mattext>
              </material>
            </response_label>
          </render_choice>
        </response_lid>
      </presentation>
      <resprocessing>
        <outcomes>
          <decvar maxvalue="100" minvalue="0" varname="SCORE" vartype="Decimal"/>
        </outcomes>
        <respcondition continue="No">
          <conditionvar>
            <varequal respident="response1">5732</varequal>
          </conditionvar>
          <setvar action="Set" varname="SCORE">100</setvar>
        </respcondition>
      </resprocessing>
    </item>
    <item ident="g87ddd5785e1ca279ecdc1147244593db" title="96abc87b-a86d-4d79-b967-0cab99a7700f">
      <itemmetadata>
        <qtimetadata>
          <qtimetadatafield>
            <fieldlabel>question_type</fieldlabel>
            <fieldentry>multiple_choice_question</fieldentry>
          </qtimetadatafield>
          <qtimetadatafield>
            <fieldlabel>points_possible</fieldlabel>
            <fieldentry>1.0</fieldentry>
          </qtimetadatafield>
          <qtimetadatafield>
            <fieldlabel>original_answer_ids</fieldlabel>
            <fieldentry>8123,5558,6817,7702</fieldentry>
          </qtimetadatafield>
        </qtimetadata>
      </itemmetadata>
      <presentation>
        <material>
          <mattext texttype="text/html">&lt;div&gt;Which of the following choices best describes how &lt;em&gt;dropout&lt;/em&gt; reduces model overfitting?&lt;/div&gt;</mattext>
        </material>
        <response_lid ident="response1" rcardinality="Single">
          <render_choice>
            <response_label ident="8123">
              <material>
                <mattext texttype="text/html">Randomly dropping nodes  forces the model to learn more randomness in the data, resulting in better generalization to unseen data.</mattext>
              </material>
            </response_label>
            <response_label ident="5558">
              <material>
                <mattext texttype="text/plain">The training is stopped early; the stopping point is decided when the performance on the validation set begins to decrease.</mattext>
              </material>
            </response_label>
            <response_label ident="6817">
              <material>
                <mattext texttype="text/plain">A predefined dropout limit is applied to the model weights; the weights are dropped when this limit is reached.</mattext>
              </material>
            </response_label>
            <response_label ident="7702">
              <material>
                <mattext texttype="text/html">"Dropping" certain features from the model before training prevents overfitting.</mattext>
              </material>
            </response_label>
          </render_choice>
        </response_lid>
      </presentation>
      <resprocessing>
        <outcomes>
          <decvar maxvalue="100" minvalue="0" varname="SCORE" vartype="Decimal"/>
        </outcomes>
        <respcondition continue="No">
          <conditionvar>
            <varequal respident="response1">8123</varequal>
          </conditionvar>
          <setvar action="Set" varname="SCORE">100</setvar>
        </respcondition>
      </resprocessing>
    </item>
    <item ident="gaebf4e62ac1a3ace4ced703186a613a6" title="Module 4 - Deploy - rubric question 4">
      <itemmetadata>
        <qtimetadata>
          <qtimetadatafield>
            <fieldlabel>question_type</fieldlabel>
            <fieldentry>multiple_choice_question</fieldentry>
          </qtimetadatafield>
          <qtimetadatafield>
            <fieldlabel>points_possible</fieldlabel>
            <fieldentry>1.0</fieldentry>
          </qtimetadatafield>
          <qtimetadatafield>
            <fieldlabel>original_answer_ids</fieldlabel>
            <fieldentry>6291,8149,3253</fieldentry>
          </qtimetadatafield>
        </qtimetadata>
      </itemmetadata>
      <presentation>
        <material>
          <mattext texttype="text/html">&lt;div&gt;Based on your sprint challenge, choose the description that most closely aligns with how well you can use the Tensorflow-Keras api to estimate a feedforward neural network&lt;/div&gt;</mattext>
        </material>
        <response_lid ident="response1" rcardinality="Single">
          <render_choice>
            <response_label ident="6291">
              <material>
                <mattext texttype="text/plain">I did not successfully implement a keras MLP model or hyperparameter tune any values.</mattext>
              </material>
            </response_label>
            <response_label ident="8149">
              <material>
                <mattext texttype="text/plain">My Keras implementation appropriately uses a sequential model with dense layers, and appropriate architecture with at least one hidden layer, activation functions, appropriate loss function, and accuracy metric. My model's verbose output shows significant improvement from the first to the last epoch during training. I showed their work in hyperparameter tuning two features and reported the CV accuracy of each parameter combination that is being tested.</mattext>
              </material>
            </response_label>
            <response_label ident="3253">
              <material>
                <mattext texttype="text/plain">My implementation is particularly elegant and readable, and well commented. Mh implementation shows a substantial increase in accuracy as it is trained. I went above and beyond in hyperparameter tuning and tunes at least 3 parameters. The combination of tuned parameters when used in the model shows a significant improvement over the baseline accuracy.

Automatic 3 if I used RandomSearchCV or another advanced optimization technique.</mattext>
              </material>
            </response_label>
          </render_choice>
        </response_lid>
      </presentation>
      <resprocessing>
        <outcomes>
          <decvar maxvalue="100" minvalue="0" varname="SCORE" vartype="Decimal"/>
        </outcomes>
        <respcondition continue="No">
          <conditionvar>
            <varequal respident="response1">8149</varequal>
          </conditionvar>
          <setvar action="Set" varname="SCORE">100</setvar>
        </respcondition>
      </resprocessing>
    </item>
    <item ident="g67b6a88022671f4c6777b17af76e5f08" title="ccc4602c-6daf-4002-ab69-19ae85b83d47">
      <itemmetadata>
        <qtimetadata>
          <qtimetadatafield>
            <fieldlabel>question_type</fieldlabel>
            <fieldentry>multiple_choice_question</fieldentry>
          </qtimetadatafield>
          <qtimetadatafield>
            <fieldlabel>points_possible</fieldlabel>
            <fieldentry>1.0</fieldentry>
          </qtimetadatafield>
          <qtimetadatafield>
            <fieldlabel>original_answer_ids</fieldlabel>
            <fieldentry>7722,2727,1222,9254</fieldentry>
          </qtimetadatafield>
        </qtimetadata>
      </itemmetadata>
      <presentation>
        <material>
          <mattext texttype="text/html">&lt;div&gt;What are 2 examples of weight decay regularization?&lt;/div&gt;</mattext>
        </material>
        <response_lid ident="response1" rcardinality="Single">
          <render_choice>
            <response_label ident="7722">
              <material>
                <mattext texttype="text/plain">L1 and L2</mattext>
              </material>
            </response_label>
            <response_label ident="2727">
              <material>
                <mattext texttype="text/plain">MaxNorm and UnitNorm</mattext>
              </material>
            </response_label>
            <response_label ident="1222">
              <material>
                <mattext texttype="text/plain">Adam and SGD</mattext>
              </material>
            </response_label>
            <response_label ident="9254">
              <material>
                <mattext texttype="text/plain">Sigmoid and Softmax</mattext>
              </material>
            </response_label>
          </render_choice>
        </response_lid>
      </presentation>
      <resprocessing>
        <outcomes>
          <decvar maxvalue="100" minvalue="0" varname="SCORE" vartype="Decimal"/>
        </outcomes>
        <respcondition continue="No">
          <conditionvar>
            <varequal respident="response1">7722</varequal>
          </conditionvar>
          <setvar action="Set" varname="SCORE">100</setvar>
        </respcondition>
      </resprocessing>
    </item>
    <item ident="gc836d2efdcf1ba6652988d75327511c8" title="d0d5776c-971e-45bd-bb32-0ef6d9fbe864">
      <itemmetadata>
        <qtimetadata>
          <qtimetadatafield>
            <fieldlabel>question_type</fieldlabel>
            <fieldentry>multiple_choice_question</fieldentry>
          </qtimetadatafield>
          <qtimetadatafield>
            <fieldlabel>points_possible</fieldlabel>
            <fieldentry>1.0</fieldentry>
          </qtimetadatafield>
          <qtimetadatafield>
            <fieldlabel>original_answer_ids</fieldlabel>
            <fieldentry>6169,2233,6159,9317</fieldentry>
          </qtimetadatafield>
        </qtimetadata>
      </itemmetadata>
      <presentation>
        <material>
          <mattext texttype="text/html">&lt;div&gt;In the example model in the Module Project (&lt;code&gt;build_complex_model&lt;/code&gt;), what happens when we apply too much regularization (larger values of the penalty) to the model weights?&lt;/div&gt;</mattext>
        </material>
        <response_lid ident="response1" rcardinality="Single">
          <render_choice>
            <response_label ident="6169">
              <material>
                <mattext texttype="text/html">The weights can decrease to zero which might limit the model's ability to learn.</mattext>
              </material>
            </response_label>
            <response_label ident="2233">
              <material>
                <mattext texttype="text/html">The weight will grow too large, resulting in a model which can't generalize well to new data.</mattext>
              </material>
            </response_label>
            <response_label ident="6159">
              <material>
                <mattext texttype="text/plain">The model will take a long time to learn and might not converge on a solution.</mattext>
              </material>
            </response_label>
            <response_label ident="9317">
              <material>
                <mattext texttype="text/html">Too many neurons will be "turned off" in the dropout layer if the regularization penalty is too high.</mattext>
              </material>
            </response_label>
          </render_choice>
        </response_lid>
      </presentation>
      <resprocessing>
        <outcomes>
          <decvar maxvalue="100" minvalue="0" varname="SCORE" vartype="Decimal"/>
        </outcomes>
        <respcondition continue="Yes">
          <conditionvar>
            <other/>
          </conditionvar>
          <displayfeedback feedbacktype="Response" linkrefid="general_fb"/>
        </respcondition>
        <respcondition continue="Yes">
          <conditionvar>
            <varequal respident="response1">2233</varequal>
          </conditionvar>
          <displayfeedback feedbacktype="Response" linkrefid="2233_fb"/>
        </respcondition>
        <respcondition continue="Yes">
          <conditionvar>
            <varequal respident="response1">6159</varequal>
          </conditionvar>
          <displayfeedback feedbacktype="Response" linkrefid="6159_fb"/>
        </respcondition>
        <respcondition continue="Yes">
          <conditionvar>
            <varequal respident="response1">9317</varequal>
          </conditionvar>
          <displayfeedback feedbacktype="Response" linkrefid="9317_fb"/>
        </respcondition>
        <respcondition continue="No">
          <conditionvar>
            <varequal respident="response1">6169</varequal>
          </conditionvar>
          <setvar action="Set" varname="SCORE">100</setvar>
        </respcondition>
      </resprocessing>
      <itemfeedback ident="general_fb">
        <flow_mat>
          <material>
            <mattext texttype="text/plain">Regularization that is too aggressive (applies too much shrinkage to the weights) will result in a poor model.</mattext>
          </material>
        </flow_mat>
      </itemfeedback>
      <itemfeedback ident="2233_fb">
        <flow_mat>
          <material>
            <mattext texttype="text/plain">Regularization "shrinks" model weights so they don't grow too large. If the penalty is too small, the weight can still grow too large.</mattext>
          </material>
        </flow_mat>
      </itemfeedback>
      <itemfeedback ident="6159_fb">
        <flow_mat>
          <material>
            <mattext texttype="text/plain">The regularization term doesn't affect how long a model takes to train but insteads affects how well a model fits the data.</mattext>
          </material>
        </flow_mat>
      </itemfeedback>
      <itemfeedback ident="9317_fb">
        <flow_mat>
          <material>
            <mattext texttype="text/plain">The regularization penalty is applied to the model weight and does not create a dropout layer in a neural network.</mattext>
          </material>
        </flow_mat>
      </itemfeedback>
    </item>
    <item ident="gde61a1af3efde2d4ee60d3f4c6464ae3" title="f4d2d155-de21-458c-9338-3dd6e3ce654a">
      <itemmetadata>
        <qtimetadata>
          <qtimetadatafield>
            <fieldlabel>question_type</fieldlabel>
            <fieldentry>multiple_choice_question</fieldentry>
          </qtimetadatafield>
          <qtimetadatafield>
            <fieldlabel>points_possible</fieldlabel>
            <fieldentry>1.0</fieldentry>
          </qtimetadatafield>
          <qtimetadatafield>
            <fieldlabel>original_answer_ids</fieldlabel>
            <fieldentry>3478,9908,3645,2052</fieldentry>
          </qtimetadatafield>
        </qtimetadata>
      </itemmetadata>
      <presentation>
        <material>
          <mattext texttype="text/html">&lt;div&gt;In the Module Project, to which layers did we apply weight decay (L1 or L2 regularization)?&lt;/div&gt;</mattext>
        </material>
        <response_lid ident="response1" rcardinality="Single">
          <render_choice>
            <response_label ident="3478">
              <material>
                <mattext texttype="text/plain">Regularization is applied to the weights for all of the hidden layers.</mattext>
              </material>
            </response_label>
            <response_label ident="9908">
              <material>
                <mattext texttype="text/plain">Only on hidden layers which have a certain number of nodes.</mattext>
              </material>
            </response_label>
            <response_label ident="3645">
              <material>
                <mattext texttype="text/plain">To the output layer.</mattext>
              </material>
            </response_label>
            <response_label ident="2052">
              <material>
                <mattext texttype="text/plain">To all of the hidden layers and the output layer.</mattext>
              </material>
            </response_label>
          </render_choice>
        </response_lid>
      </presentation>
      <resprocessing>
        <outcomes>
          <decvar maxvalue="100" minvalue="0" varname="SCORE" vartype="Decimal"/>
        </outcomes>
        <respcondition continue="Yes">
          <conditionvar>
            <other/>
          </conditionvar>
          <displayfeedback feedbacktype="Response" linkrefid="general_fb"/>
        </respcondition>
        <respcondition continue="Yes">
          <conditionvar>
            <varequal respident="response1">9908</varequal>
          </conditionvar>
          <displayfeedback feedbacktype="Response" linkrefid="9908_fb"/>
        </respcondition>
        <respcondition continue="Yes">
          <conditionvar>
            <varequal respident="response1">3645</varequal>
          </conditionvar>
          <displayfeedback feedbacktype="Response" linkrefid="3645_fb"/>
        </respcondition>
        <respcondition continue="Yes">
          <conditionvar>
            <varequal respident="response1">2052</varequal>
          </conditionvar>
          <displayfeedback feedbacktype="Response" linkrefid="2052_fb"/>
        </respcondition>
        <respcondition continue="No">
          <conditionvar>
            <varequal respident="response1">3478</varequal>
          </conditionvar>
          <setvar action="Set" varname="SCORE">100</setvar>
        </respcondition>
      </resprocessing>
      <itemfeedback ident="general_fb">
        <flow_mat>
          <material>
            <mattext texttype="text/plain">The reduce model complexity and prevent overfitting, we apply regularization to all the hidden layers in our model.</mattext>
          </material>
        </flow_mat>
      </itemfeedback>
      <itemfeedback ident="9908_fb">
        <flow_mat>
          <material>
            <mattext texttype="text/plain">The reduce model complexity and prevent overfitting, we apply regularization to all the hidden layers in our model.</mattext>
          </material>
        </flow_mat>
      </itemfeedback>
      <itemfeedback ident="3645_fb">
        <flow_mat>
          <material>
            <mattext texttype="text/plain">The output layer isn't regularized. The reduce model complexity and prevent overfitting, we apply regularization to all the hidden layers in our model.</mattext>
          </material>
        </flow_mat>
      </itemfeedback>
      <itemfeedback ident="2052_fb">
        <flow_mat>
          <material>
            <mattext texttype="text/plain">The output layer isn't regularized. The reduce model complexity and prevent overfitting, we apply regularization to all the hidden layers in our model.</mattext>
          </material>
        </flow_mat>
      </itemfeedback>
    </item>
  </objectbank>
</questestinterop>
