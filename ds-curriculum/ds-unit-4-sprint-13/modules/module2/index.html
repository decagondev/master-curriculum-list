<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Module 2: Vector Representations</title>
    <link rel="stylesheet" href="../../assets/css/style.css">
</head>
<body>
    <div class="container">
        <header>
            <nav>
                <div class="logo">Data Science Unit 4</div>
                <ul>
                    <li><a href="../../index.html" class="active">Home</a></li>
                    <li class="dropdown">
                        <a href="#">Modules</a>
                        <div class="dropdown-content">
                            <a href="../module1/index.html">Module 1: Natural Language Processing - Introduction</a>
                            <a href="../module2/index.html">Module 2: Vector Representations</a>
                            <a href="../module3/index.html">Module 3: Document Classification</a>
                            <a href="../module4/index.html">Module 4: Topic Modeling</a>
                        </div>
                    </li>
                    <li><a href="../../code-alongs/index.html">Code-Alongs</a></li>
                    <li><a href="../../sprint-challenge/index.html">Sprint Challenge</a></li>
                </ul>
            </nav>
        </header>
        
        <main>
            <h1>Module 2: Vector Representations</h1>
            <section id="module-overview">
                <h2>Module Overview</h2>
                <p>In this module, we'll explore vector representations of text data, a crucial step in making text processable by machine learning algorithms. We'll learn how to convert documents into numerical vectors, measure similarity between documents, and apply word embedding models to capture semantic relationships between words. These techniques form the foundation for document retrieval, recommendation systems, and more advanced NLP applications.</p>
            </section>

            <section id="learning-objectives">
                <h2>Learning Objectives</h2>
                
                <h3>1. Represent a document as a vector</h3>
                <p>
                    • Convert text documents into numerical vector representations<br>
                    • Implement bag-of-words and document-term matrices<br>
                    • Apply term frequency-inverse document frequency (TF-IDF) weighting<br>
                    • Compare different vector representation methods
                </p>

                <h3>2. Query documents by similarity</h3>
                <p>
                    • Calculate similarity between document vectors<br>
                    • Implement cosine similarity for comparing documents<br>
                    • Create document retrieval systems based on vector similarity<br>
                    • Evaluate the quality of document similarity measures
                </p>

                <h3>3. Apply word embedding models</h3>
                <p>
                    • Understand the principles behind word embedding models<br>
                    • Use pre-trained word vectors for document representation<br>
                    • Create document vectors from word embeddings<br>
                    • Compare traditional vector representations with embedding-based approaches
                </p>
            </section>

            <section id="guided-project">
                <h2>Guided Project</h2>
                <h3>Vector Representations for NLP</h3>
                
                <div class="video-container">
                    <iframe class="wistia_embed" title="Sprint 13 Vector Representations Video" src="https://fast.wistia.net/embed/iframe/lrewwnm3kn" width="640" height="360" name="wistia_embed" allow="autoplay; fullscreen" loading="lazy"></iframe>
                </div>
                
                <p>
                    <a href="https://github.com/bloominstituteoftechnology/DS-Unit-4-Sprint-1-NLP/tree/main/module2-vector-representations" target="_blank" rel="noopener">GitHub Repo</a> | 
                    <a href="https://docs.google.com/presentation/d/1tLERo2WqCrvMHTubHp-BAYAT3RU-7JcuTUy2lW7ly18/edit?usp=sharing" target="_blank" rel="noopener">Slides</a>
                </p>

                <h3>Guided Project File:</h3>
                <p>DS_412_Vector_Representations_Lecture_GP.ipynb</p>
            </section>

            <section id="module-assignment">
                <h2>Module Assignment</h2>
                <p>Please read the assignment file in the GitHub repository for detailed instructions on completing your assignment tasks.</p>
                
                <h3>Assignment File:</h3>
                <p>DS_412_Vector_Representations_Assignment.ipynb</p>

                <p>In this assignment, you will work with job listings data for Data Scientists to practice text vectorization techniques. Your tasks include:</p>
                <ul>
                    <li>Cleaning HTML from job listings using BeautifulSoup</li>
                    <li>Tokenizing text with spaCy and creating custom preprocessing functions</li>
                    <li>Creating document-term matrices using CountVectorizer</li>
                    <li>Visualizing word frequency distributions</li>
                    <li>Implementing TF-IDF vectorization for improved text representation</li>
                    <li>Creating a nearest neighbor model to find similar job listings based on a query</li>
                </ul>

                <h3>Assignment Solution Video</h3>
                <div class="video-container">
                    <iframe class="wistia_embed" title="DS_412_Vector_Representations_Assignment_Solution Video" src="https://fast.wistia.net/embed/iframe/zjaq65sntg" width="640" height="360" name="wistia_embed" allow="autoplay; fullscreen" loading="lazy"></iframe>
                </div>
            </section>

            <section id="check-for-understanding">
                <h2>Check for Understanding</h2>
                <p>Complete the following items to test your understanding:</p>
                <ul>
                    <li>Create document vectors using bag-of-words and TF-IDF approaches</li>
                    <li>Compare two documents using cosine similarity</li>
                    <li>Implement document retrieval based on vector similarity</li>
                    <li>Create document vectors using word embeddings</li>
                    <li>Visualize the distribution of terms in a document corpus</li>
                </ul>
            </section>

            <section id="additional-resources">
                <h2>Additional Resources</h2>
                <ul>
                    <li><a href="https://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction" target="_blank" rel="noopener">Scikit-Learn: Text Feature Extraction</a></li>
                    <li><a href="https://radimrehurek.com/gensim/auto_examples/tutorials/run_word2vec.html" target="_blank" rel="noopener">Gensim: Word2Vec Tutorial</a></li>
                    <li><a href="https://nlp.stanford.edu/projects/glove/" target="_blank" rel="noopener">Stanford NLP: GloVe - Global Vectors for Word Representation</a></li>
                    <li><a href="https://web.stanford.edu/~jurafsky/slp3/6.pdf" target="_blank" rel="noopener">Vector Semantics and Embeddings - Chapter from Speech and Language Processing</a></li>
                    <li><a href="https://towardsdatascience.com/calculating-document-similarities-using-bert-and-other-models-b2c1a29c9630" target="_blank" rel="noopener">Calculating Document Similarities Using BERT and Other Models</a></li>
                    <li><a href="https://www.tensorflow.org/tutorials/text/word_embeddings" target="_blank" rel="noopener">TensorFlow: Word Embeddings</a></li>
                </ul>
            </section>
        </main>
    </div>
</body>
</html> 