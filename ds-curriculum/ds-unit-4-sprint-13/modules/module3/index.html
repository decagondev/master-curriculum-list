<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Module 3: Document Classification</title>
    <link rel="stylesheet" href="../../assets/css/style.css">
</head>
<body>
    <div class="container">
        <header>
            <nav>
                <div class="logo">Data Science Unit 4</div>
                <ul>
                    <li><a href="../../index.html" class="active">Home</a></li>
                    <li class="dropdown">
                        <a href="#">Modules</a>
                        <div class="dropdown-content">
                            <a href="../module1/index.html">Module 1: Natural Language Processing - Introduction</a>
                            <a href="../module2/index.html">Module 2: Vector Representations</a>
                            <a href="../module3/index.html">Module 3: Document Classification</a>
                            <a href="../module4/index.html">Module 4: Topic Modeling</a>
                        </div>
                    </li>
                    <li><a href="../../code-alongs/index.html">Code-Alongs</a></li>
                    <li><a href="../../sprint-challenge/index.html">Sprint Challenge</a></li>
                </ul>
            </nav>
        </header>

        <main>
            <h1>Module 3: Document Classification</h1>
            <section id="module-overview">
                <h2>Module Overview</h2>
                <p>In this module, we'll explore document classification, a fundamental NLP task that involves categorizing text documents into predefined classes. We'll learn how to extract features from text data, implement classification pipelines, apply dimensionality reduction techniques like Latent Semantic Indexing (LSI), and benchmark different vectorization methods to optimize classification performance. These skills are essential for applications such as sentiment analysis, spam detection, and topic categorization.</p>
            </section>

            <section id="learning-objectives">
                <h2>Learning Objectives</h2>
                
                <h3>1. Extract text features and use them in classification pipelines</h3>
                <p>
                    • Transform text data into numerical features suitable for machine learning<br>
                    • Implement bag-of-words and TF-IDF vectorization for text data<br>
                    • Create end-to-end classification pipelines with scikit-learn<br>
                    • Optimize feature extraction parameters in classification workflows
                </p>

                <h3>2. Apply Latent Semantic Indexing (LSI) to a document classification problem</h3>
                <p>
                    • Understand the principles behind Latent Semantic Indexing<br>
                    • Implement LSI using Truncated SVD for dimensionality reduction<br>
                    • Integrate LSI into classification pipelines<br>
                    • Evaluate the impact of LSI on classification performance
                </p>

                <h3>3. Benchmark different vectorization methods in document classification tasks</h3>
                <p>
                    • Compare performance of various text vectorization approaches<br>
                    • Evaluate traditional methods against word embedding techniques<br>
                    • Apply cross-validation to reliably measure model performance<br>
                    • Select optimal vectorization methods for specific classification tasks
                </p>
            </section>

            <section id="guided-project">
                <h2>Guided Project</h2>
                <h3>Document Classification for NLP</h3>
                
                <div class="video-container">
                    <iframe class="wistia_embed" title="Sprint 13 Document Classification Video" src="https://fast.wistia.net/embed/iframe/38c1houbbl" width="640" height="360" name="wistia_embed" allow="autoplay; fullscreen" loading="lazy"></iframe>
                </div>
                
                <p>
                    <a href="https://github.com/bloominstituteoftechnology/DS-Unit-4-Sprint-1-NLP/tree/main/module3-document-classification" target="_blank" rel="noopener">GitHub Repo</a> | 
                    <a href="https://docs.google.com/presentation/d/1Vvl-M7IYKqeoPzQ9mFOOob7Wax1Onh_TeHBuYZOu7OM/edit?usp=sharing" target="_blank" rel="noopener">Slides</a>
                </p>
                
                <h3>Guided Project File:</h3>
                <p>DS_413_Document_Classification_Lecture_GP.ipynb</p>
            </section>

            <section id="module-assignment">
                <h2>Module Assignment</h2>
                <p>Please read the assignment file in the GitHub repository for detailed instructions on completing your assignment tasks.</p>
                
                <h3>Assignment File:</h3>
                <p>DS_413_Document_Classification_Assignment.ipynb</p>

                <p>In this assignment, you'll participate in a Kaggle competition to classify whisky reviews. The assignment is divided into multiple parts where you'll apply and compare different NLP techniques:</p>
                <ul>
                    <li>Part 1: Implement text feature extraction and classification pipelines using TF-IDF vectorization</li>
                    <li>Part 2: Apply Latent Semantic Indexing (LSI) to improve your document classification model</li>
                    <li>Part 3: Explore word embeddings with spaCy to create document vectors for classification</li>
                    <li>Part 4: Submit your best model to Kaggle and aim for a minimum of 80% accuracy</li>
                </ul>
                
                <p>Throughout the assignment, you'll clean text data, tune hyperparameters, build nested pipelines, and benchmark different vectorization methods to optimize classification performance.</p>

                <h3>Assignment Solution Video</h3>
                <div class="video-container">
                    <iframe class="wistia_embed" title="DS_413_Document_Classification_Assignment_Solutions Video" src="https://fast.wistia.net/embed/iframe/x8yi2jf4ch" width="640" height="360" name="wistia_embed" allow="autoplay; fullscreen" loading="lazy"></iframe>
                </div>
            </section>

            <section id="check-for-understanding">
                <h2>Check for Understanding</h2>
                <p>Complete the following items to test your understanding:</p>
                <ul>
                    <li>Create a classification pipeline with TF-IDF vectorization and a machine learning classifier</li>
                    <li>Implement LSI using Truncated SVD and explain its effect on your model</li>
                    <li>Compare the performance of different vectorization methods on a text classification task</li>
                    <li>Tune hyperparameters using grid search or randomized search with cross-validation</li>
                    <li>Visualize and interpret the most important features for classification</li>
                </ul>
            </section>

            <section id="additional-resources">
                <h2>Additional Resources</h2>
                <ul>
                    <li><a href="https://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction" target="_blank" rel="noopener">Scikit-Learn: Text Feature Extraction</a></li>
                    <li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.TruncatedSVD.html" target="_blank" rel="noopener">Scikit-Learn: Truncated SVD for LSI</a></li>
                    <li><a href="https://www.kaggle.com/c/word2vec-nlp-tutorial" target="_blank" rel="noopener">Kaggle: Bag of Words Meets Bags of Popcorn</a></li>
                    <li><a href="https://machinelearningmastery.com/develop-word-embedding-model-predicting-movie-review-sentiment/" target="_blank" rel="noopener">Embeddings Sentiment Analysis</a></li>
                </ul>
            </section>
        </main>
    </div>
</body>
</html>